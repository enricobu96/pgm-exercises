{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Models – Spring 2022\n",
    "## Exercise Session 2\n",
    "Return by Feb 8th 12.00 through Moodle. Session on Feb 8th 14.15.\n",
    "\n",
    "<span style=\"color:red\">**Enrico Buratto**</span>\n",
    "\n",
    "### Instructions\n",
    "Make sure the notebook produces correct results when ran sequentially starting from the first cell. You can ensure this by clearing all outputs (`Edit > Clear All Outputs`), running all cells (`Run > Run All Cells`), and finally correcting any errors.\n",
    "\n",
    "To get points:\n",
    "1. Submit your answers to the automatically checked Moodle test. \n",
    " - You have 5 tries on the test: the highest obtained score will be taken into account.\n",
    " - For numerical questions the tolerance varies by question and will be specified in Moodle.\n",
    "2. Submit this notebook containing your derivations to Moodle.\n",
    "\n",
    "Some of the exercises will ask you to return a DAG as an answer. To make it possible to evaluate the answer automatically in Moodle use the following format. Construct the DAG as an adjacency matrix where $A[i, j] = 1$ if there is an edge $j \\rightarrow i$ and 0 otherwise. The nodes should be in alphabetical order, so $A \\rightarrow B$ corresponds to $0 \\rightarrow 1$ (or $1 \\rightarrow 2$ in R's 1-based indexing). Finally, concatenate all the rows starting from the first one and submit the vector as your answer. For example the DAG $A \\rightarrow B \\leftarrow C$ is encoded by the matrix \n",
    "\n",
    "$$\\begin{bmatrix} 0 & 0 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 0 & 0 \\end{bmatrix}$$\n",
    "\n",
    "and vector $000101000$.\n",
    "\n",
    "You can make use of the following examples to construct the DAG with Python/R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000101000\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS IF WORKING IN PYTHON\n",
    "import pandas as pd\n",
    "\n",
    "# Function to concatenate matrix rows into a single string\n",
    "def mat2vec(dag):\n",
    "    return ''.join(str(x) for x in dag.values.reshape(dag.values.shape[0]**2))\n",
    "\n",
    "# Adjacency matrix\n",
    "rvs = [\"A\", \"B\", \"C\"]\n",
    "DAG = pd.DataFrame(0, index=rvs, columns=rvs)\n",
    "\n",
    "# Example: Set parents of B to be A and C.\n",
    "DAG.loc[\"B\", [\"A\", \"C\"]] = 1\n",
    "\n",
    "# Create the vector\n",
    "print(mat2vec(DAG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000101000"
     ]
    }
   ],
   "source": [
    "# RUN THIS IF WORKING IN R\n",
    "\n",
    "# Function to concatenate matrix rows into a single string\n",
    "mat2vec <- function(dag) {\n",
    "    return(paste(apply(dag, 1, paste, collapse=\"\"), collapse=\"\"))\n",
    "}\n",
    "\n",
    "# Adjacency matrix\n",
    "rvs <- c(\"A\", \"B\", \"C\")\n",
    "DAG <- data.frame(matrix(0L, ncol = 3, nrow = 3))\n",
    "colnames(DAG) <- rvs\n",
    "rownames(DAG) <- rvs\n",
    "\n",
    "# Example: Set parents of B to be A and C.\n",
    "DAG[\"B\", c(\"A\", \"C\")] <- 1\n",
    "\n",
    "# Create the vector\n",
    "cat(mat2vec(DAG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "***\n",
    "\n",
    "Let us consider a 4-sided dice rolling experiment as a multinomial model (i.i.d.   multi-valued Bernoulli). We roll the dice 20 times, and observe data $D$ with the following counts for the sides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side\tcounts\n",
      "1\t5\n",
      "2\t3\n",
      "3\t7\n",
      "4\t5\n"
     ]
    }
   ],
   "source": [
    "!cat data/1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Calculate the maximum likelihood parameters, given the above data.\n",
    "\n",
    "(b) Calculate the posterior distribution $P(\\theta_1, \\theta_2, \\theta_3, \\theta_4 | D)$ considering the prior $Dir(\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4)$, with\n",
    "- $\\alpha_1 = \\alpha_2 = \\alpha_3 = \\alpha_4 = 1$, i.e., the uniform prior and\n",
    "- $\\alpha_1 = \\alpha_2 = \\alpha_3 = \\alpha_4 = 0.5$, i.e., the Jeffrey's prior.\n",
    "\n",
    "For both, report the mean. \n",
    "\n",
    "(c) Using Bayesian inference with the uniform prior (above), calculate the predictive distribution (all 4 probabilities) of the next result given $D$.\n",
    "\n",
    "(d) Let $\\alpha_4$, the 4th hyperparameter to the Dirichlet prior be 3. Specify $\\alpha_1$, $\\alpha_2$ and $\\alpha_3$ such that the mode of the posterior distribution is at $\\theta_1 = \\theta_2 = \\theta_3 = \\theta_4$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task a\n",
    "\n",
    "We can expand what we saw in class considering $N_A$ = parameter of which we are searching the maximum likelihood parameter, say $N$, and $N_B$ the others, say $M$. We then derive the likelihood function and we put it to zero to find the maximum: $$ \\frac{d}{d\\theta}P(D|\\theta) = 0$$ And we find as well that $$\\theta=\\frac{N}{N+M}$$\n",
    "\n",
    "#### Task b\n",
    "\n",
    "We know that the mean of a Dirichlet distribution is $$E[X_i]=\\frac{\\alpha_i}{\\sum_{k=1}^{K}a_k}$$ and that the posterior distribution is proportional to the prior; to be more specific, if the prior is $Dir(\\theta;\\alpha_1,...,\\alpha_k)$, the posterior is $Dir(\\theta;\\alpha_1+N_1,...,\\alpha_k+N_k)$. The mean of the posterior distribution is then $$E[X_i]=\\frac{x_i+\\alpha_i}{\\sum_{k=1}^{K}x_k\\alpha_k}$$\n",
    "\n",
    "#### Task c\n",
    "\n",
    "Bayesian inference can be done with model averaging; the formula is equal to the mean of a Dirichlet distribution, so the results are the same.\n",
    "\n",
    "#### Task d\n",
    "\n",
    "We know that the mode of a Dirichlet distribution is $$\\theta_i = \\frac{\\alpha_i-1}{\\sum_{k=1}^{K}\\alpha_k-K}$$ the mode of the posterior distribution is then $$\\theta_i = \\frac{\\alpha_i+x_i-1}{\\sum_{k=1}^{K}\\alpha_k+x_k-K}$$ for the same proportionality property we saw for the mean. Now, for $\\theta_4$ we have that $$\\theta_4 = \\frac{3+5-1}{\\sum_{k=1}^{K}\\alpha_k+x_k-K}$$ and we must have $\\theta_4=\\theta_1=\\theta_2=\\theta_3$, so $$\\theta_1=\\frac{\\alpha_1+5-1}{\\sum_{k=1}^{K}\\alpha_k+x_k-K}$$ therefore, it's trivial that $\\alpha_1=3$ (they have the same numerical parameters). We also have that for every $\\theta$ the denominator is equal, so now we can just calculate the other $\\alpha$ saying that $\\alpha_1+5-1=\\alpha_2+3-1=\\alpha_3+7-1=\\alpha_4+5-1$. So, finally:\n",
    "- $\\alpha_1=3$\n",
    "- $\\alpha_2=5$\n",
    "- $\\alpha_3=1$\n",
    "- $\\alpha_4=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task a\n",
      "Side 0\n",
      "ML 0.25\n",
      "Side 1\n",
      "ML 0.15\n",
      "Side 2\n",
      "ML 0.35\n",
      "Side 3\n",
      "ML 0.25\n",
      "\n",
      "Task b\n",
      "Alpha=1\n",
      "Side 0\n",
      "Mean 0.25\n",
      "Side 1\n",
      "Mean 0.16666666666666666\n",
      "Side 2\n",
      "Mean 0.3333333333333333\n",
      "Side 3\n",
      "Mean 0.25\n",
      "Alpha=0.5\n",
      "Side 0\n",
      "Mean 0.25\n",
      "Side 1\n",
      "Mean 0.1590909090909091\n",
      "Side 2\n",
      "Mean 0.3409090909090909\n",
      "Side 3\n",
      "Mean 0.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/1.csv', sep='\\t')\n",
    "\n",
    "# Task a\n",
    "print('Task a')\n",
    "t = df['counts'].sum() # N+M\n",
    "for side, count in df.iterrows():\n",
    "    print('Side', side)\n",
    "    print('ML', count['counts']/t)\n",
    "\n",
    "# Task b\n",
    "print('\\nTask b')\n",
    "def calculate_mean(df, alpha):\n",
    "    t = df['counts'].sum()\n",
    "    for side, count in df.iterrows():\n",
    "        print('Side', side)\n",
    "        p = (count['counts']+alpha)/(t+4*alpha)\n",
    "        print('Mean', p)\n",
    "print('Alpha=1')\n",
    "calculate_mean(df,1)\n",
    "print('Alpha=0.5')\n",
    "calculate_mean(df,.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "***\n",
    "\n",
    "Show by using the d-separation criterion that a node in a Bayesian network is conditionally independent of all the other nodes, given its (minimal) Markov blanket (parents, children, spouses (parents of children)). \n",
    "\n",
    "Give the answer verbally in Moodle. It will be checked manually. For your own future reference it's a good idea to paste the answer here, too. \n",
    "\n",
    "Some correct and incorrect proofs will be posted anonymously in Moodle for study, by returning you agree that your version may be published anonymously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "In order to prove that a node in a Bayesian network is conditionally independent of all the other nodes, given its Markov blanket, we can use the **Global Markov property**, that is defined as follows (ref. [COMP538, Hong Kong University](https://cse.hkust.edu.hk/bnbook/pdf/l03.h.pdf)):\n",
    "\n",
    "Given a Bayesian network, let $X$ and $Y$ be two variables and $\\bold{Z}$ to be a set of variables that does not contain $X$ or $Y$. If $\\bold{Z}$ d-separates $X$ and $Y$, then $X\\mathrel{⫫}Y|\\bold{Z}$.\n",
    "\n",
    "Then, a variable $X$ is conditionally independent of all other variables given its Markov blanket: the Markov blanket of X, in fact, d-separates X from all other nodes because in any path starting from $X$ and going outside the Markov blanket of $X$ the connection at the last node before leaving the blanket could be (using Darwiche's book naming) sequential or diverging, so the path is always blocked. $\\square$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "***\n",
    "\n",
    "Consider the following BN structure. Answer the following queries and questions, justifying your answers.\n",
    "\n",
    "![](2.3.svg)\n",
    "\n",
    "(a) Decide whether the following d-separations hold or not. \n",
    "- $G \\mathrel{⫫}_{G} D \\mid A, E$\n",
    "- $D \\mathrel{⫫}_{G} F$\n",
    "- $H \\mathrel{⫫}_{G} B \\mid G, C$\n",
    "- $G \\mathrel{⫫}_{G} H \\mid A, F$\n",
    "\n",
    "(b) Construct a Markov equivalent DAG (other than the given), and return it to Moodle in the format specified at the top of the notebook. How many equivalent DAGs are there in total (including the given one)?\n",
    "\n",
    "(c) Suppose all variables in this network are binary. How many free parameters are needed to parameterize this network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task a\n",
    "\n",
    "In order to verify is a d-separation holds or not we can use the valve system, described also in Darwiche's book. We have that:\n",
    "\n",
    "Let $\\bold{X}$, $\\bold{Y}$ and $\\bold{Z}$ be disjointed sets of nodes in a DAG _G_, we say that $\\bold{X}$ and $\\bold{Y}$ are _d-separated_ by $\\bold{Z}$ if and only if every path between a node $\\bold{X}$ and a node $\\bold{Y}$ is blocked by $\\bold{Z}$. A path is blocked by $\\bold{X}$ if and only if at least one valve on the path is closed given $\\bold{Z}$.\n",
    "\n",
    "We can have three different valves, that are closed under certain conditions:\n",
    "- **Sequential valve**: -> W ->. This is closed if and only if the variable W appears in $\\bold{Z}$;\n",
    "- **Divergent valve**: <- W ->. This is closed if and only if the variable W appears in $\\bold{Z}$;\n",
    "- **Convergent valve**: -> W <-. This is closed if and only if neither variable W nor any of its descendants appear in $\\bold{Z}$.\n",
    "\n",
    "We then have that:\n",
    "- $G \\mathrel{⫫}_{G} D \\mid A, E$ **does not hold** because G->F->B, F->B->A, B->A<-C and A<-C-> are open;\n",
    "- $D \\mathrel{⫫}_{G} F$ **holds** because B->A<-C and F->B<-E are closed (if we are considering $D \\mathrel{⫫}_{G} F$ given all the remaining set);\n",
    "- $H \\mathrel{⫫}_{G} B \\mid G, C$ **does not hold** because H->E->B is open;\n",
    "- $G \\mathrel{⫫}_{G} H \\mid A, F$ **holds** beacuse G->F->B is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0110000000001100000010000010000000000000000000100000000000001000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Task b\n",
    "\n",
    "Two DAGs are Markov equivalent if and only if they have the\n",
    "same skeleton (structure omitting edge directions) and the same\n",
    "set of (unshielded) v-structures (X → Y ← Z , no edge between Z\n",
    "and X , also called immorality).\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to concatenate matrix rows into a single string\n",
    "def mat2vec(dag):\n",
    "    return ''.join(str(x) for x in dag.values.reshape(dag.values.shape[0]**2))\n",
    "\n",
    "# Adjacency matrix\n",
    "rvs = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "DAG = pd.DataFrame(0, index=rvs, columns=rvs)\n",
    "\n",
    "# This is the DAG in the picture\n",
    "DAG.loc[\"A\", [\"B\", \"C\"]] = 1\n",
    "DAG.loc[\"B\", [\"E\", \"F\"]] = 1\n",
    "DAG.loc[\"F\", \"G\"] = 1\n",
    "DAG.loc[\"E\", \"H\"] = 1\n",
    "DAG.loc[\"C\", \"E\"] = 1\n",
    "DAG.loc[\"D\", \"C\"] = 1\n",
    "\n",
    "# We can change a \"secure\" connection in order to have a Markov equivalent DAG\n",
    "DAG.loc[\"E\", \"H\"] = 0\n",
    "DAG.loc[\"H\", \"E\"] = 1\n",
    "\n",
    "# There are 8 equivalent DAGs: different combinations of H-E, G-F, C-D\n",
    "\n",
    "# Create the vector\n",
    "print(mat2vec(DAG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task c\n",
    "\n",
    "In order to calculate the number of free parameters needed to parameterize this network we can calculate the factorization using the chain rule. We than have $$P(G)P(H)P(F|G)P(B|F,E)P(A|B,C)P(E|H)P(C|E)P(D|C) = 1+1+2+4+4+2+2+2 = 18$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "***\n",
    "\n",
    "Consider again the DAG in Exercise 3.\n",
    "\n",
    "a) What is the factorization implied by the DAG?\n",
    "\n",
    "Return the factorization in Moodle in plain text in the exact same format as the example: `P(A,B,C)P(B,C|D)P(C|E,F)`. Here\n",
    "- a set of variables $\\{ B, A, C \\}$ is encoded as `A,B,C` (note the alphabetical order);\n",
    "- the factors themselves are in alphabetical order, so not `P(B)P(A)` but `P(A)P(B)`, not `P(A|C)P(A|B)` but `P(A|B)P(A|C)`.\n",
    "\n",
    "b) Which of the following independencies are stated by the local Markov condition asserted by the DAG?\n",
    "\n",
    "- $D \\mathrel{⫫} F$\n",
    "- $E \\mathrel{⫫} A \\mid H$\n",
    "- $B \\mathrel{⫫} H \\mid F, G$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task a\n",
    "\n",
    "The factorization is the one calculated on the exercise above. Using the order requested it is $$P(A|B,C)P(B|E,F)P(C|E)P(D|C)P(E|H)P(F|G)P(G)P(H)$$\n",
    "\n",
    "#### Task b\n",
    "\n",
    "A distribution P satisfies the local Markov property if and only if $X\\mathrel{⫫}Nondesc(X)|Parents(X)$ holds for all variables $X$. So:\n",
    "\n",
    "- $D \\mathrel{⫫} F$ **does not hold** because parents are not given;\n",
    "- $E \\mathrel{⫫} A \\mid H$ **does not hold** because $A$ is in fact a descendant of $E$;\n",
    "- $B \\mathrel{⫫} H \\mid F, G$ **does not hold** beacuse it's true that $F$ and $G$ are parents of $B$, but $H$ and $E$ are parents as well and they are not given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "***\n",
    "\n",
    "Consider the following DAG: $X \\rightarrow Y \\rightarrow Z$.\n",
    "\n",
    "(a) Suppose the variables are binary and another, equivalent DAG encodes the same joint distribution with the following parameters:\n",
    "\n",
    "\\begin{aligned}\n",
    "P(Y = 1) = 0.3 \\\\\n",
    "P(X = 1 | Y = 1) = 0.2 \\\\\n",
    "P(X = 1 | Y = 0) = 0.8 \\\\\n",
    "P(Z = 1 | Y = 1) = 0.8 \\\\\n",
    "P(Z = 1 | Y = 0) = 0.2 \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "Give the parameters corresponding to the first DAG.\n",
    "\n",
    "(b) What values do the variables take at the mode of the joint distribution?\n",
    "\n",
    "(c) Compute the marginal probabilities $P(X)$, $P(Y)$, $P(Z)$ and their respective most probable arguments (which value for each random variable gets the highest probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your answer in cells here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "***\n",
    "\n",
    "Faithfulness. Consider a DAG $X \\rightarrow Y$ over binary random variables $X,Y$.\n",
    "\n",
    "(a) Give parameters for a BN over the DAG such that we have $X \\mathrel{⫫} Y$ (conditional independence) and the distribution is positive, i.e., gives a non-zero probability for all assignments of $X,Y$.\n",
    "\n",
    "(b) Give parameters for a BN over the DAG such that we have $X \\not\\mathrel{⫫} Y$ such that the distribution is positive as well.\n",
    "\n",
    "(c) Take the parameters in (a), add small random noise to the parameters and renormalize the probabilities such that you have a (valid) BN (i.e. rows of CPTs should sum up to one and all probabilities should be positive). Do you still have $X \\mathrel{⫫} Y$?\n",
    "\n",
    "(d) Does any of this contradict the soundness and completeness of d-separation? Why?\n",
    "\n",
    "For each part give a short verbal answer in Moodle, e.g., \"P(X = 1) = x, P(Y = 1 | X = 1) = y, P(Y = 1 | X = 0) = z  ...\". They will be graded manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task a\n",
    "\n",
    "Conditional independence between two variables means that both their conditioned probabilities are the same as the unconditioned, _i.e._ $P(X|Y) = P(X)$ and $P(Y|X) = P(Y)$. This task then reduces to find the parameters such that, for every $X=\\{0,1\\}$ $$P(X)=P(X|Y=0)=P(X|Y=1)$$ and viceversa with Y being the conditioned event and X being the conditioning event. This could hold for this \"chain\" of probabilities equal to 0.5 in order to have the distribution normalized.\n",
    "\n",
    "#### Task b\n",
    "\n",
    "It's sufficent to add some noise to the parameters.\n",
    "\n",
    "#### Task c\n",
    "\n",
    "Same as task b.\n",
    "\n",
    "#### Task d\n",
    "\n",
    "On the contrary, this prove what is stated on the slides, _i.e._ to create a BN whose distribution induces additional unfaithful independencies requires fine hand-tuning of the parameters, and adding even small perturbations on the parameters will destroy independencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
